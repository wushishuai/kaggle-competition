{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 构建模型\n",
    "# 导入GBDT算法\n",
    "from sklearn.ensemble import GradientBoostingRegressor #梯度提升算法\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split,KFold,cross_val_score #划分数据集包，交叉验证包\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn import neighbors\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn import ensemble\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn import tree\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "# 特征标准化\n",
    "all_features = pd.concat((train_data.iloc[:, 1:-1], test_data.iloc[:, 1:]))\n",
    "# # 若无法获得测试数据，则可根据训练数据计算均值和标准差\n",
    "# numeric_features = all_features.dtypes[all_features.dtypes != 'object'].index\n",
    "# all_features[numeric_features] = all_features[numeric_features].apply(\n",
    "#     lambda x: (x - x.mean()) / (x.std()))\n",
    "# # 在标准化数据之后，所有均值消失，因此我们可以将缺失值设置为0\n",
    "# all_features[numeric_features] = all_features[numeric_features].fillna(0)\n",
    "# ExterQual ExterCond  BsmtQual BsmtCond BsmtExposure BsmtFinType1 BsmtFinType2 HeatingQC KitchenQual FireplaceQu GarageQual GarageCond PoolQC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "qual_map={'Po':1.0,'Fa':2.0,'TA':3.0,'Gd':4.0,'Ex':5.0}#ExterQual  ExterCond HeatingQC KitchenQual\n",
    "qual2_map={'NA':0.0,'Po':1.0,'Fa':2.0,'TA':3.0,'Gd':4.0,'Ex':5.0}#BsmtQual BsmtCond FireplaceQu GarageQual GarageCond\n",
    "qual3_map={'NA':0.0,'No':1.0,'Mn':2.0,'Av':3.0,'Gd':4.0}#BsmtExposure\n",
    "qual4_map={'NA':0.0,'Unf':1.0,'LwQ':2.0,'Rec':3.0,'BLQ':4.0,'ALQ':5.0,'GLQ':6.0}#BsmtFinType1 BsmtFinType2\n",
    "qual5_map={'NA':0.0,'Fa':1.0,'TA':2.0,'Gd':3.0,'Ex':4.0}#PoolQC\n",
    "all_features['ExterQual']=all_features['ExterQual'].map(qual_map)\n",
    "all_features['ExterCond']=all_features['ExterCond'].map(qual_map)\n",
    "all_features['HeatingQC']=all_features['HeatingQC'].map(qual_map)\n",
    "all_features['KitchenQual']=all_features['KitchenQual'].map(qual_map)\n",
    "all_features['BsmtQual']=all_features['BsmtQual'].map(qual2_map)\n",
    "all_features['BsmtCond']=all_features['BsmtCond'].map(qual2_map)\n",
    "all_features['FireplaceQu']=all_features['FireplaceQu'].map(qual2_map)\n",
    "all_features['GarageQual']=all_features['GarageQual'].map(qual2_map)\n",
    "all_features['GarageCond']=all_features['GarageCond'].map(qual2_map)\n",
    "all_features['BsmtExposure']=all_features['BsmtExposure'].map(qual3_map)\n",
    "all_features['BsmtFinType1']=all_features['BsmtFinType1'].map(qual4_map)\n",
    "all_features['BsmtFinType2']=all_features['BsmtFinType2'].map(qual4_map)\n",
    "all_features['PoolQC']=all_features['PoolQC'].map(qual5_map)\n",
    "# 若无法获得测试数据，则可根据训练数据计算均值和标准差\n",
    "numeric_features = all_features.dtypes[all_features.dtypes != 'object'].index\n",
    "all_features[numeric_features] = all_features[numeric_features].apply(\n",
    "    lambda x: (x - x.mean()) / (x.std()))\n",
    "# 在标准化数据之后，所有均值消失，因此我们可以将缺失值设置为0\n",
    "all_features[numeric_features] = all_features[numeric_features].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_features = pd.get_dummies(all_features, dummy_na=True)\n",
    "n_train = train_data.shape[0]\n",
    "train_features = all_features[:n_train].values\n",
    "test_features = all_features[n_train:].values\n",
    "train_labels = train_data.SalePrice.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "# 特征标准化\n",
    "all_features = pd.concat((train_data.iloc[:, 1:-1], test_data.iloc[:, 1:]))\n",
    "# 若无法获得测试数据，则可根据训练数据计算均值和标准差\n",
    "numeric_features = all_features.dtypes[all_features.dtypes != 'object'].index\n",
    "all_features[numeric_features] = all_features[numeric_features].apply(\n",
    "    lambda x: (x - x.mean()) / (x.std()))\n",
    "# 在标准化数据之后，所有均值消失，因此我们可以将缺失值设置为0\n",
    "all_features[numeric_features] = all_features[numeric_features].fillna(0)\n",
    "# “Dummy_na=True”将“na”（缺失值）视为有效的特征值，并为其创建指示符特征\n",
    "all_features = pd.get_dummies(all_features, dummy_na=True)\n",
    "all_features.shape\n",
    "n_train = train_data.shape[0]\n",
    "train_features = all_features[:n_train].values\n",
    "test_features = all_features[n_train:].values\n",
    "train_labels = train_data.SalePrice.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "# 定义验证函数,使用5折交叉验证，采用均方根误差判别，返回均方根误差\n",
    "def rmse_cv(model):\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=0)# 划分成五分\n",
    "    cvs=cross_val_score(model,train_features,train_labels,scoring=\"neg_mean_squared_log_error\",cv = 5) #这里是输入了x,y\n",
    "    #这里的cv参数为分配器, 返回每一次交叉验证的估计量分数数组\n",
    "    #这里返回的是每组方差的负数\n",
    "    # print(cvs)\n",
    "    #返回误差\n",
    "    rmse= np.sqrt(-cvs)\n",
    "    # print(rmse)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\application\\anaconda3\\envs\\d2l\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\application\\anaconda3\\envs\\d2l\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\application\\anaconda3\\envs\\d2l\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\application\\anaconda3\\envs\\d2l\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\application\\anaconda3\\envs\\d2l\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting score: RSME=0.1246 (SD=0.0114)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 构建一个GBDT的实例用来验证其准确率\n",
    "GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.005,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10,\n",
    "                                   loss='huber', random_state =5)\n",
    "#loss：损失函数，ls是最小二乘，lad是最小绝对偏差，huber是前两者的结合\n",
    "#learning_rate:学习率决定了参数移动到最优值的速度快慢，学习率过大可能越过最优值，学习率过小可能会减缓收敛速度。\n",
    "#max_depth:限制了树的节点，可以调整这个数字来获得最优表现\n",
    "#max_features:  这个max_features=sqrt(n_features)\n",
    "#min_samples_split：每个叶子节点所需要的最小样本数\n",
    "#n_estimators： 提升学习过程被终止时基分类器的最大数量。一个强大的参数，一般都是先调整它\n",
    "# random_state：这里的random_state就是为了保证程序每次运行都分割一样的训练集和测试集。否则，同样的算法模型在不同的训练集和测试集上的效果不一样。\n",
    "#当你用sklearn分割完测试集和训练集，确定模型和初始参数以后，你会发现程序每运行一次，都会得到不同的准确率，无法调参。这个时候就是因为没有加random_state。加上以后就可以调参了。\n",
    "\n",
    "score1 = rmse_cv(GBoost)\n",
    "# 输出五个均方根误差的平均值RSME和其标准差SD,保留4位小数\n",
    "print(\"Gradient Boosting score: RSME={:.4f} (SD={:.4f})\\n\".format(score1.mean(),score1.std()))#Gradient Boosting score: RSME=0.1247 (SD=0.0123) Gradient Boosting score: RSME=0.1246 (SD=0.0114)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 构建一个GBDT的实例用来验证其准确率\n",
    "GBoost = GradientBoostingRegressor(random_state =6)\n",
    "#loss：损失函数，ls是最小二乘，lad是最小绝对偏差，huber是前两者的结合\n",
    "#learning_rate:学习率决定了参数移动到最优值的速度快慢，学习率过大可能越过最优值，学习率过小可能会减缓收敛速度。\n",
    "#max_depth:限制了树的节点，可以调整这个数字来获得最优表现\n",
    "#max_features:  这个max_features=sqrt(n_features)\n",
    "#min_samples_split：每个叶子节点所需要的最小样本数\n",
    "#n_estimators： 提升学习过程被终止时基分类器的最大数量。一个强大的参数，一般都是先调整它\n",
    "# random_state：这里的random_state就是为了保证程序每次运行都分割一样的训练集和测试集。否则，同样的算法模型在不同的训练集和测试集上的效果不一样。\n",
    "#当你用sklearn分割完测试集和训练集，确定模型和初始参数以后，你会发现程序每运行一次，都会得到不同的准确率，无法调参。这个时候就是因为没有加random_state。加上以后就可以调参了。\n",
    "\n",
    "# score1 = rmse_cv(GBoost)\n",
    "# # 输出五个均方根误差的平均值RSME和其标准差SD,保留4位小数\n",
    "# print(\"Gradient Boosting score: RSME={:.4f} (SD={:.4f})\\n\".format(score1.mean(),score1.std()))#Gradient Boosting score: RSME=0.1315 (SD=0.0097) Gradient Boosting score: RSME=0.1292 (SD=0.0101)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\application\\anaconda3\\envs\\d2l\\lib\\site-packages\\sklearn\\ensemble\\_stacking.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\application\\anaconda3\\envs\\d2l\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\application\\anaconda3\\envs\\d2l\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\application\\anaconda3\\envs\\d2l\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\application\\anaconda3\\envs\\d2l\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\application\\anaconda3\\envs\\d2l\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\application\\anaconda3\\envs\\d2l\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\application\\anaconda3\\envs\\d2l\\lib\\site-packages\\sklearn\\ensemble\\_stacking.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\application\\anaconda3\\envs\\d2l\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\application\\anaconda3\\envs\\d2l\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\application\\anaconda3\\envs\\d2l\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\application\\anaconda3\\envs\\d2l\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\application\\anaconda3\\envs\\d2l\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\application\\anaconda3\\envs\\d2l\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\application\\anaconda3\\envs\\d2l\\lib\\site-packages\\sklearn\\ensemble\\_stacking.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\application\\anaconda3\\envs\\d2l\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\application\\anaconda3\\envs\\d2l\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\application\\anaconda3\\envs\\d2l\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\application\\anaconda3\\envs\\d2l\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\application\\anaconda3\\envs\\d2l\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\application\\anaconda3\\envs\\d2l\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\application\\anaconda3\\envs\\d2l\\lib\\site-packages\\sklearn\\ensemble\\_stacking.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\application\\anaconda3\\envs\\d2l\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\application\\anaconda3\\envs\\d2l\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\application\\anaconda3\\envs\\d2l\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\application\\anaconda3\\envs\\d2l\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\application\\anaconda3\\envs\\d2l\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\application\\anaconda3\\envs\\d2l\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\application\\anaconda3\\envs\\d2l\\lib\\site-packages\\sklearn\\ensemble\\_stacking.py:752: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "D:\\application\\anaconda3\\envs\\d2l\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\application\\anaconda3\\envs\\d2l\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\application\\anaconda3\\envs\\d2l\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\application\\anaconda3\\envs\\d2l\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\application\\anaconda3\\envs\\d2l\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "D:\\application\\anaconda3\\envs\\d2l\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting score: RSME=0.1343 (SD=0.0098)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SVM回归\n",
    "model_SVR = svm.SVR()\n",
    "#knn回归\n",
    "model_KNN = neighbors.KNeighborsRegressor()\n",
    "model_ML = MLPRegressor(hidden_layer_sizes=(100,50), activation='relu',solver='adam',\n",
    "    alpha=0.01,max_iter=200)\n",
    "#Adaboot回归\n",
    "#决策树回归\n",
    "xgb_reg = xgboost.XGBRegressor()\n",
    "model_DT = tree.DecisionTreeRegressor(random_state=50)\n",
    "model_ABR = ensemble.AdaBoostRegressor(random_state=70)\n",
    "model_RFR = ensemble.RandomForestRegressor(random_state=30)\n",
    "estimators = [('ml',model_ML),('xgb',xgb_reg)]\n",
    "stack = StackingRegressor(estimators=estimators,final_estimator=GBoost)\n",
    "score1 = rmse_cv(stack)\n",
    "# 输出五个均方根误差的平均值RSME和其标准差SD,保留4位小数\n",
    "print(\"Gradient Boosting score: RSME={:.4f} (SD={:.4f})\\n\".format(score1.mean(),score1.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting score: RSME=0.1381 (SD=0.0069)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_reg = xgboost.XGBRegressor()\n",
    "score1 = rmse_cv(xgb_reg)\n",
    "# 输出五个均方根误差的平均值RSME和其标准差SD,保留4位小数\n",
    "print(\"Gradient Boosting score: RSME={:.4f} (SD={:.4f})\\n\".format(score1.mean(),score1.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
